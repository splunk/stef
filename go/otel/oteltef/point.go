// Code generated by stefgen. DO NOT EDIT.
package oteltef

import (
	"bytes"
	"fmt"
	"math/rand/v2"
	"strings"
	"unsafe"

	"github.com/splunk/stef/go/pkg"
	"github.com/splunk/stef/go/pkg/encoders"
	"github.com/splunk/stef/go/pkg/schema"
)

var _ = strings.Compare
var _ = encoders.StringEncoder{}
var _ = schema.WireSchema{}
var _ = bytes.NewBuffer

type Point struct {
	startTimestamp uint64
	timestamp      uint64
	value          PointValue
	exemplars      ExemplarArray

	// modifiedFields keeps track of which fields are modified.
	modifiedFields modifiedFields
}

const PointStructName = "Point"

// Bitmasks for "modified" flags for each field.
const (
	fieldModifiedPointStartTimestamp = uint64(1 << iota)
	fieldModifiedPointTimestamp
	fieldModifiedPointValue
	fieldModifiedPointExemplars
)

// Init must be called once, before the Point is used.
func (s *Point) Init() {
	s.init(nil, 0)
}

func NewPoint() *Point {
	var s Point
	s.init(nil, 0)
	return &s
}

func (s *Point) init(parentModifiedFields *modifiedFields, parentModifiedBit uint64) {
	s.modifiedFields.parent = parentModifiedFields
	s.modifiedFields.parentBit = parentModifiedBit

	s.value.init(&s.modifiedFields, fieldModifiedPointValue)
	s.exemplars.init(&s.modifiedFields, fieldModifiedPointExemplars)
}

func (s *Point) initAlloc(parentModifiedFields *modifiedFields, parentModifiedBit uint64, allocators *Allocators) {
	s.modifiedFields.parent = parentModifiedFields
	s.modifiedFields.parentBit = parentModifiedBit

	s.value.initAlloc(&s.modifiedFields, fieldModifiedPointValue, allocators)
	s.exemplars.initAlloc(&s.modifiedFields, fieldModifiedPointExemplars, allocators)
}

// reset the struct to its initial state, as if init() was just called.
// Will not reset internal fields such as parentModifiedFields.
func (s *Point) reset() {

	s.startTimestamp = 0
	s.timestamp = 0
	s.value.reset()
	s.exemplars.reset()
}

// fixParent sets the parentModifiedFields pointer to the supplied value.
// This is used when the parent is moved in memory for example because the parent
// an array element and the array was expanded.
func (s *Point) fixParent(parentModifiedFields *modifiedFields) {
	s.modifiedFields.parent = parentModifiedFields

	s.value.fixParent(&s.modifiedFields)
	s.exemplars.fixParent(&s.modifiedFields)
}

func (s *Point) StartTimestamp() uint64 {
	return s.startTimestamp
}

// SetStartTimestamp sets the value of StartTimestamp field.
func (s *Point) SetStartTimestamp(v uint64) {
	if !pkg.Uint64Equal(s.startTimestamp, v) {
		s.startTimestamp = v
		s.markStartTimestampModified()
	}
}

func (s *Point) markStartTimestampModified() {
	s.modifiedFields.markModified(fieldModifiedPointStartTimestamp)
}

// IsStartTimestampModified returns true the value of StartTimestamp field was modified since
// Point was created, encoded or decoded. If the field is modified
// it will be encoded by the next Write() operation. If the field is decoded by the
// next Read() operation the modified flag will be set.
func (s *Point) IsStartTimestampModified() bool {
	return s.modifiedFields.mask&fieldModifiedPointStartTimestamp != 0
}

func (s *Point) Timestamp() uint64 {
	return s.timestamp
}

// SetTimestamp sets the value of Timestamp field.
func (s *Point) SetTimestamp(v uint64) {
	if !pkg.Uint64Equal(s.timestamp, v) {
		s.timestamp = v
		s.markTimestampModified()
	}
}

func (s *Point) markTimestampModified() {
	s.modifiedFields.markModified(fieldModifiedPointTimestamp)
}

// IsTimestampModified returns true the value of Timestamp field was modified since
// Point was created, encoded or decoded. If the field is modified
// it will be encoded by the next Write() operation. If the field is decoded by the
// next Read() operation the modified flag will be set.
func (s *Point) IsTimestampModified() bool {
	return s.modifiedFields.mask&fieldModifiedPointTimestamp != 0
}

func (s *Point) Value() *PointValue {
	return &s.value
}

func (s *Point) markValueModified() {
	s.modifiedFields.markModified(fieldModifiedPointValue)
}

// IsValueModified returns true the value of Value field was modified since
// Point was created, encoded or decoded. If the field is modified
// it will be encoded by the next Write() operation. If the field is decoded by the
// next Read() operation the modified flag will be set.
func (s *Point) IsValueModified() bool {
	return s.modifiedFields.mask&fieldModifiedPointValue != 0
}

func (s *Point) Exemplars() *ExemplarArray {
	return &s.exemplars
}

func (s *Point) markExemplarsModified() {
	s.modifiedFields.markModified(fieldModifiedPointExemplars)
}

// IsExemplarsModified returns true the value of Exemplars field was modified since
// Point was created, encoded or decoded. If the field is modified
// it will be encoded by the next Write() operation. If the field is decoded by the
// next Read() operation the modified flag will be set.
func (s *Point) IsExemplarsModified() bool {
	return s.modifiedFields.mask&fieldModifiedPointExemplars != 0
}

func (s *Point) markModifiedRecursively() {

	s.value.markModifiedRecursively()

	s.exemplars.markModifiedRecursively()

	s.modifiedFields.mask =
		fieldModifiedPointStartTimestamp |
			fieldModifiedPointTimestamp |
			fieldModifiedPointValue |
			fieldModifiedPointExemplars | 0
}

func (s *Point) markUnmodifiedRecursively() {

	if s.IsStartTimestampModified() {
	}

	if s.IsTimestampModified() {
	}

	if s.IsValueModified() {
		s.value.markUnmodifiedRecursively()
	}

	if s.IsExemplarsModified() {
		s.exemplars.markUnmodifiedRecursively()
	}

	s.modifiedFields.mask = 0
}

func (s *Point) Clone(allocators *Allocators) Point {

	c := Point{

		startTimestamp: s.startTimestamp,
		timestamp:      s.timestamp,
		value:          s.value.Clone(allocators),
		exemplars:      s.exemplars.Clone(allocators),
	}
	c.modifiedFields.hash = s.modifiedFields.hash
	return c
}

// ByteSize returns approximate memory usage in bytes. Used to calculate
// memory used by dictionaries.
func (s *Point) byteSize() uint {
	return uint(unsafe.Sizeof(*s)) +
		s.value.byteSize() + s.exemplars.byteSize() + 0
}

// Copy from src to dst, overwriting existing data in dst.
func copyPoint(dst *Point, src *Point) {
	dst.SetStartTimestamp(src.startTimestamp)
	dst.SetTimestamp(src.timestamp)
	copyPointValue(&dst.value, &src.value)
	copyExemplarArray(&dst.exemplars, &src.exemplars)
	if src.modifiedFields.hash != 0 {
		dst.modifiedFields.hash = src.modifiedFields.hash
	}
}

// Copy from src to dst. dst is assumed to be just inited.
func copyToNewPoint(dst *Point, src *Point, allocators *Allocators) {
	dst.startTimestamp = src.startTimestamp
	dst.timestamp = src.timestamp
	copyToNewPointValue(&dst.value, &src.value, allocators)
	copyToNewExemplarArray(&dst.exemplars, &src.exemplars, allocators)
	dst.modifiedFields.hash = src.modifiedFields.hash
}

// CopyFrom() performs a deep copy from src.
func (s *Point) CopyFrom(src *Point) {
	copyPoint(s, src)
}

func (s *Point) markParentModified() {
	s.modifiedFields.parent.markModified(s.modifiedFields.parentBit)
}

// mutateRandom mutates fields in a random, deterministic manner using
// random parameter as a deterministic generator. Only fields that exist
// in the schem are mutated, allowing to generate data for specified schema.
func (s *Point) mutateRandom(random *rand.Rand, schem *schema.Schema) {
	// Get the field count for this struct from the schema. If the schema specifies
	// fewer field count than the one we have in this code then we will not mutate
	// fields that are not in the schema.
	fieldCount, err := schem.FieldCount("Point")
	if err != nil {
		panic(fmt.Sprintf("cannot get field count for %s: %v", "Point", err))
	}

	const randRange = max(4, 2) // At least 2 to ensure we don't recurse infinitely if there is only 1 field.

	if fieldCount <= 0 {
		return // StartTimestamp and all subsequent fields are skipped.
	}
	// Maybe mutate StartTimestamp
	if random.IntN(randRange) == 0 {
		s.SetStartTimestamp(pkg.Uint64Random(random))
	}
	if fieldCount <= 1 {
		return // Timestamp and all subsequent fields are skipped.
	}
	// Maybe mutate Timestamp
	if random.IntN(randRange) == 0 {
		s.SetTimestamp(pkg.Uint64Random(random))
	}
	if fieldCount <= 2 {
		return // Value and all subsequent fields are skipped.
	}
	// Maybe mutate Value
	if random.IntN(randRange) == 0 {
		s.value.mutateRandom(random, schem)
	}
	if fieldCount <= 3 {
		return // Exemplars and all subsequent fields are skipped.
	}
	// Maybe mutate Exemplars
	if random.IntN(randRange) == 0 {
		s.exemplars.mutateRandom(random, schem)
	}
}

// IsEqual performs deep comparison and returns true if struct is equal to right.
func (s *Point) IsEqual(right *Point) bool {
	if s == nil {
		return right == nil
	}
	if s.modifiedFields.hash != 0 && right.modifiedFields.hash != 0 {
		if s.modifiedFields.hash != right.modifiedFields.hash {
			return false
		}
	}
	// Compare StartTimestamp field.
	if !pkg.Uint64Equal(s.startTimestamp, right.startTimestamp) {
		return false
	}
	// Compare Timestamp field.
	if !pkg.Uint64Equal(s.timestamp, right.timestamp) {
		return false
	}
	// Compare Value field.
	if !s.value.IsEqual(&right.value) {
		return false
	}
	// Compare Exemplars field.
	if !s.exemplars.IsEqual(&right.exemplars) {
		return false
	}

	return true
}

func PointEqual(left, right *Point) bool {
	return left.IsEqual(right)
}

func (s *Point) Hash() uint64 {
	if s == nil {
		return 0
	}
	if s.modifiedFields.hash != 0 {
		return s.modifiedFields.hash
	}

	hash := uint64(15530645482203505416)
	hash ^= pkg.Uint64Hash(s.startTimestamp)
	hash ^= pkg.Uint64Hash(s.timestamp)
	hash ^= s.value.Hash()
	hash ^= s.exemplars.Hash()
	hash |= 1 // Make sure it is never 0
	s.modifiedFields.hash = hash
	return hash
}

// CmpPoint performs deep comparison and returns an integer that
// will be 0 if left == right, negative if left < right, positive if left > right.
func CmpPoint(left, right *Point) int {
	if left == nil {
		if right == nil {
			return 0
		}
		return -1
	}
	if right == nil {
		return 1
	}

	// Compare StartTimestamp field.
	if c := pkg.Uint64Compare(left.startTimestamp, right.startTimestamp); c != 0 {
		return c
	}

	// Compare Timestamp field.
	if c := pkg.Uint64Compare(left.timestamp, right.timestamp); c != 0 {
		return c
	}

	// Compare Value field.
	if c := CmpPointValue(&left.value, &right.value); c != 0 {
		return c
	}

	// Compare Exemplars field.
	if c := CmpExemplarArray(&left.exemplars, &right.exemplars); c != 0 {
		return c
	}

	return 0
}

// PointEncoder implements encoding of Point
type PointEncoder struct {
	buf     pkg.BitsWriter
	limiter *pkg.SizeLimiter

	// forceModifiedFields is set to true if the next encoding operation
	// must write all fields, whether they are modified or no.
	// This is used after frame restarts so that the data can be decoded
	// from the frame start.
	forceModifiedFields bool

	startTimestampEncoder encoders.Uint64Encoder

	timestampEncoder encoders.Uint64Encoder

	valueEncoder     *PointValueEncoder
	isValueRecursive bool // Indicates Value field's type is recursive.

	exemplarsEncoder     *ExemplarArrayEncoder
	isExemplarsRecursive bool // Indicates Exemplars field's type is recursive.

	allocators *Allocators

	keepFieldMask uint64
	fieldCount    uint
}

func (e *PointEncoder) Init(state *WriterState, columns *pkg.WriteColumnSet) error {
	// Remember this encoder in the state so that we can detect recursion.
	if state.PointEncoder != nil {
		panic("cannot initialize PointEncoder: already initialized")
	}
	state.PointEncoder = e
	defer func() { state.PointEncoder = nil }()

	e.limiter = &state.limiter
	e.allocators = &state.Allocators

	// Number of fields in the output data schema.
	var err error
	e.fieldCount, err = state.StructFieldCounts.PointFieldCount()
	if err != nil {
		return fmt.Errorf("cannot find struct %s in override schema: %v", "Point", err)
	}
	// Set that many 1 bits in the keepFieldMask. All fields with higher number
	// will be skipped when encoding.
	e.keepFieldMask = ^(^uint64(0) << e.fieldCount)

	// Init encoder for StartTimestamp field.
	if e.fieldCount <= 0 {
		return nil // StartTimestamp and all subsequent fields are skipped.
	}
	err = e.startTimestampEncoder.Init(e.limiter, columns.AddSubColumn())
	if err != nil {
		return err
	}

	// Init encoder for Timestamp field.
	if e.fieldCount <= 1 {
		return nil // Timestamp and all subsequent fields are skipped.
	}
	err = e.timestampEncoder.Init(e.limiter, columns.AddSubColumn())
	if err != nil {
		return err
	}

	// Init encoder for Value field.
	if e.fieldCount <= 2 {
		return nil // Value and all subsequent fields are skipped.
	}
	if state.PointValueEncoder != nil {
		// Recursion detected, use the existing encoder.
		e.valueEncoder = state.PointValueEncoder
		e.isValueRecursive = true
	} else {
		e.valueEncoder = new(PointValueEncoder)
		err = e.valueEncoder.Init(state, columns.AddSubColumn())
	}
	if err != nil {
		return err
	}

	// Init encoder for Exemplars field.
	if e.fieldCount <= 3 {
		return nil // Exemplars and all subsequent fields are skipped.
	}
	if state.ExemplarArrayEncoder != nil {
		// Recursion detected, use the existing encoder.
		e.exemplarsEncoder = state.ExemplarArrayEncoder
		e.isExemplarsRecursive = true
	} else {
		e.exemplarsEncoder = new(ExemplarArrayEncoder)
		err = e.exemplarsEncoder.Init(state, columns.AddSubColumn())
	}
	if err != nil {
		return err
	}

	return nil
}

func (e *PointEncoder) Reset() {
	// Since we are resetting the state of encoder make sure the next Encode()
	// call forcedly writes all fields and does not attempt to skip.
	e.forceModifiedFields = true

	if e.fieldCount <= 0 {
		return // StartTimestamp and all subsequent fields are skipped.
	}
	e.startTimestampEncoder.Reset()
	if e.fieldCount <= 1 {
		return // Timestamp and all subsequent fields are skipped.
	}
	e.timestampEncoder.Reset()
	if e.fieldCount <= 2 {
		return // Value and all subsequent fields are skipped.
	}

	if !e.isValueRecursive {
		e.valueEncoder.Reset()
	}

	if e.fieldCount <= 3 {
		return // Exemplars and all subsequent fields are skipped.
	}

	if !e.isExemplarsRecursive {
		e.exemplarsEncoder.Reset()
	}

}

// Encode encodes val into buf
func (e *PointEncoder) Encode(val *Point) {
	var bitCount uint

	// Mask that describes what fields are encoded. Start with all modified fields.
	fieldMask := val.modifiedFields.mask

	// If forceModifiedFields we need to set to 1 all bits so that we
	// force writing of all fields.
	if e.forceModifiedFields {
		fieldMask =
			fieldModifiedPointStartTimestamp |
				fieldModifiedPointTimestamp |
				fieldModifiedPointValue |
				fieldModifiedPointExemplars | 0
	}

	// Only write fields that we want to write. See Init() for keepFieldMask.
	fieldMask &= e.keepFieldMask

	// Write bits to indicate which fields follow.
	e.buf.WriteBits(fieldMask, e.fieldCount)
	bitCount += e.fieldCount

	// Encode modified, present fields.

	if fieldMask&fieldModifiedPointStartTimestamp != 0 {
		// Encode StartTimestamp
		e.startTimestampEncoder.Encode(val.startTimestamp)
	}

	if fieldMask&fieldModifiedPointTimestamp != 0 {
		// Encode Timestamp
		e.timestampEncoder.Encode(val.timestamp)
	}

	if fieldMask&fieldModifiedPointValue != 0 {
		// Encode Value
		e.valueEncoder.Encode(&val.value)
	}

	if fieldMask&fieldModifiedPointExemplars != 0 {
		// Encode Exemplars
		e.exemplarsEncoder.Encode(&val.exemplars)
	}

	// Account written bits in the limiter.
	e.limiter.AddFrameBits(bitCount)

	// Mark all fields non-modified so that next Encode() correctly
	// encodes only fields that change after this.
	val.modifiedFields.mask = 0
}

// CollectColumns collects all buffers from all encoders into buf.
func (e *PointEncoder) CollectColumns(columnSet *pkg.WriteColumnSet) {
	columnSet.SetBits(&e.buf)
	colIdx := 0

	// Collect StartTimestamp field.
	if e.fieldCount <= 0 {
		return // StartTimestamp and subsequent fields are skipped.
	}

	e.startTimestampEncoder.CollectColumns(columnSet.At(colIdx))
	colIdx++

	// Collect Timestamp field.
	if e.fieldCount <= 1 {
		return // Timestamp and subsequent fields are skipped.
	}

	e.timestampEncoder.CollectColumns(columnSet.At(colIdx))
	colIdx++

	// Collect Value field.
	if e.fieldCount <= 2 {
		return // Value and subsequent fields are skipped.
	}
	if !e.isValueRecursive {
		e.valueEncoder.CollectColumns(columnSet.At(colIdx))
		colIdx++
	}

	// Collect Exemplars field.
	if e.fieldCount <= 3 {
		return // Exemplars and subsequent fields are skipped.
	}
	if !e.isExemplarsRecursive {
		e.exemplarsEncoder.CollectColumns(columnSet.At(colIdx))
		colIdx++
	}
}

// PointDecoder implements decoding of Point
type PointDecoder struct {
	buf        pkg.BitsReader
	column     *pkg.ReadableColumn
	fieldCount uint

	startTimestampDecoder encoders.Uint64Decoder

	timestampDecoder encoders.Uint64Decoder

	valueDecoder     *PointValueDecoder
	isValueRecursive bool

	exemplarsDecoder     *ExemplarArrayDecoder
	isExemplarsRecursive bool

	allocators *Allocators
}

// Init is called once in the lifetime of the stream.
func (d *PointDecoder) Init(state *ReaderState, columns *pkg.ReadColumnSet) error {
	// Remember this decoder in the state so that we can detect recursion.
	if state.PointDecoder != nil {
		panic("cannot initialize PointDecoder: already initialized")
	}
	state.PointDecoder = d
	defer func() { state.PointDecoder = nil }()

	d.allocators = &state.Allocators

	// Number of fields in the input data schema.
	var err error
	d.fieldCount, err = state.StructFieldCounts.PointFieldCount()
	if err != nil {
		return fmt.Errorf("cannot find struct %s in override schema: %v", "Point", err)
	}

	d.column = columns.Column()

	if d.fieldCount <= 0 {
		return nil // StartTimestamp and subsequent fields are skipped.
	}
	err = d.startTimestampDecoder.Init(columns.AddSubColumn())
	if err != nil {
		return err
	}
	if d.fieldCount <= 1 {
		return nil // Timestamp and subsequent fields are skipped.
	}
	err = d.timestampDecoder.Init(columns.AddSubColumn())
	if err != nil {
		return err
	}
	if d.fieldCount <= 2 {
		return nil // Value and subsequent fields are skipped.
	}
	if state.PointValueDecoder != nil {
		// Recursion detected, use the existing decoder.
		d.valueDecoder = state.PointValueDecoder
		d.isValueRecursive = true // Mark that we are using a recursive decoder.
	} else {
		d.valueDecoder = new(PointValueDecoder)
		err = d.valueDecoder.Init(state, columns.AddSubColumn())
	}
	if err != nil {
		return err
	}
	if d.fieldCount <= 3 {
		return nil // Exemplars and subsequent fields are skipped.
	}
	if state.ExemplarArrayDecoder != nil {
		// Recursion detected, use the existing decoder.
		d.exemplarsDecoder = state.ExemplarArrayDecoder
		d.isExemplarsRecursive = true // Mark that we are using a recursive decoder.
	} else {
		d.exemplarsDecoder = new(ExemplarArrayDecoder)
		err = d.exemplarsDecoder.Init(state, columns.AddSubColumn())
	}
	if err != nil {
		return err
	}

	return nil
}

// Continue is called at the start of the frame to continue decoding column data.
// This should set the decoder's source buffer, so the new decoding continues from
// the supplied column data. This should NOT reset the internal state of the decoder,
// since columns can cross frame boundaries and the new column data is considered
// continuation of that same column in the previous frame.
func (d *PointDecoder) Continue() {
	d.buf.Reset(d.column.Data())

	if d.fieldCount <= 0 {
		return // StartTimestamp and subsequent fields are skipped.
	}
	d.startTimestampDecoder.Continue()
	if d.fieldCount <= 1 {
		return // Timestamp and subsequent fields are skipped.
	}
	d.timestampDecoder.Continue()
	if d.fieldCount <= 2 {
		return // Value and subsequent fields are skipped.
	}

	if !d.isValueRecursive {
		d.valueDecoder.Continue()
	}

	if d.fieldCount <= 3 {
		return // Exemplars and subsequent fields are skipped.
	}

	if !d.isExemplarsRecursive {
		d.exemplarsDecoder.Continue()
	}

}

func (d *PointDecoder) Reset() {

	if d.fieldCount <= 0 {
		return // StartTimestamp and all subsequent fields are skipped.
	}
	d.startTimestampDecoder.Reset()
	if d.fieldCount <= 1 {
		return // Timestamp and all subsequent fields are skipped.
	}
	d.timestampDecoder.Reset()
	if d.fieldCount <= 2 {
		return // Value and all subsequent fields are skipped.
	}

	if !d.isValueRecursive {
		d.valueDecoder.Reset()
	}

	if d.fieldCount <= 3 {
		return // Exemplars and all subsequent fields are skipped.
	}

	if !d.isExemplarsRecursive {
		d.exemplarsDecoder.Reset()
	}

}

func (d *PointDecoder) Decode(dstPtr *Point) error {
	val := dstPtr

	var err error

	// Read bits that indicate which fields follow.
	val.modifiedFields.mask = d.buf.ReadBits(d.fieldCount)

	if val.modifiedFields.mask&fieldModifiedPointStartTimestamp != 0 {
		// Field is changed and is present, decode it.
		err = d.startTimestampDecoder.Decode(&val.startTimestamp)
		if err != nil {
			return err
		}
	}

	if val.modifiedFields.mask&fieldModifiedPointTimestamp != 0 {
		// Field is changed and is present, decode it.
		err = d.timestampDecoder.Decode(&val.timestamp)
		if err != nil {
			return err
		}
	}

	if val.modifiedFields.mask&fieldModifiedPointValue != 0 {
		// Field is changed and is present, decode it.
		err = d.valueDecoder.Decode(&val.value)
		if err != nil {
			return err
		}
	}

	if val.modifiedFields.mask&fieldModifiedPointExemplars != 0 {
		// Field is changed and is present, decode it.
		err = d.exemplarsDecoder.Decode(&val.exemplars)
		if err != nil {
			return err
		}
	}

	return nil
}

// PointAllocator implements a custom allocator for Point.
// It maintains a pool of pre-allocated Point and grows the pool
// dynamically as needed, up to a maximum size of 64 elements.
type PointAllocator struct {
	pool []Point
	ofs  int
}

// Alloc returns the next available Point from the pool.
// If the pool is exhausted, it grows the pool by doubling its size
// up to a maximum of 64 elements.
func (a *PointAllocator) Alloc() *Point {
	if a.ofs < len(a.pool) {
		// Get the next available Point from the pool
		a.ofs++
		return &a.pool[a.ofs-1]
	}
	// We've exhausted the current pool, prealloc a new pool.
	return a.prealloc()
}

//go:noinline
func (a *PointAllocator) prealloc() *Point {
	// prealloc expands the pool by doubling its size, up to a maximum of 64 elements.
	// If the pool is empty, it starts with 1 element.
	newLen := min(max(len(a.pool)*2, 1), 64)
	a.pool = make([]Point, newLen)
	a.ofs = 1
	return &a.pool[0]
}
