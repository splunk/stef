// Code generated by stefc. DO NOT EDIT.
package jsonstef

import (
	"math/rand/v2"

	"strings"
	"unsafe"

	"github.com/splunk/stef/go/pkg"
	"github.com/splunk/stef/go/pkg/codecs"
	"github.com/splunk/stef/go/pkg/schema"
)

var _ = (*codecs.StringEncoder)(nil)
var _ = (*strings.Builder)(nil)

// JsonValueArray is a variable size array.
type JsonValueArray struct {
	elems       []*JsonValue // all pointers are non-nil
	initedCount int

	parentModifiedFields *modifiedFields
	parentModifiedBit    uint64
}

func (e *JsonValueArray) init(parentModifiedFields *modifiedFields, parentModifiedBit uint64) {
	e.parentModifiedFields = parentModifiedFields
	e.parentModifiedBit = parentModifiedBit
}

func (e *JsonValueArray) initAlloc(parentModifiedFields *modifiedFields, parentModifiedBit uint64, allocators *Allocators) {
	e.init(parentModifiedFields, parentModifiedBit)
}

// reset the array to its initial state, as if init() was just called.
// Will not reset internal fields such as parentModifiedFields.
func (e *JsonValueArray) reset() {
	e.elems = e.elems[:0]
}

func (e *JsonValueArray) freeze() {
	for i := 0; i < len(e.elems); i++ {
		e.elems[i].freeze()
	}
}

// fixParent sets the parentModifiedFields pointer to the supplied value.
// This is used when the parent is moved in memory for example because the parent
// an array element and the array was expanded.
func (e *JsonValueArray) fixParent(parentModifiedFields *modifiedFields) {
	e.parentModifiedFields = parentModifiedFields
}

func (e *JsonValueArray) canBeShared() bool {
	// An array can never be shared.
	return false
}

// ByteSize returns approximate memory usage in bytes. Used to calculate
// memory used by dictionaries.
func (e *JsonValueArray) byteSize() uint {
	if len(e.elems) == 0 {
		return 0
	}
	// TODO: add size of elements if they are clonable.
	size := uint(unsafe.Sizeof(e.elems[0]))*uint(len(e.elems)) + uint(unsafe.Sizeof(e))

	for i := range e.elems {
		size += e.elems[i].byteSize()
	}
	return size
}

// Append a new element at the end of the array.
func (e *JsonValueArray) Append(val *JsonValue) {
	e.elems = append(e.elems, val)
	e.markModified()
}

func (e *JsonValueArray) markModified() {
	e.parentModifiedFields.markModified(e.parentModifiedBit)
}

func (e *JsonValueArray) setModifiedRecursively() {
	for i := 0; i < len(e.elems); i++ {
		e.elems[i].setModifiedRecursively()
	}

}

func (e *JsonValueArray) setUnmodifiedRecursively() {
	for i := 0; i < len(e.elems); i++ {
		e.elems[i].setUnmodifiedRecursively()
	}

}

// computeDiff compares e and val and returns true if they differ.
// All fields that are different in e will be marked as modified.
func (e *JsonValueArray) computeDiff(val *JsonValueArray) (ret bool) {
	if len(e.elems) != len(val.elems) {
		ret = true
	}
	minLen := min(len(e.elems), len(val.elems))
	i := 0
	for ; i < minLen; i++ {
		if e.elems[i].computeDiff(val.elems[i]) {
			ret = true
		}
	}
	for ; i < len(e.elems); i++ {
		e.elems[i].setModifiedRecursively()
	}
	return ret
}

// Copy from src to dst, overwriting existing data in dst.
func copyJsonValueArray(dst *JsonValueArray, src *JsonValueArray) {
	isModified := false

	minLen := min(len(dst.elems), len(src.elems))
	if len(dst.elems) != len(src.elems) {
		dst.EnsureLen(len(src.elems))
		isModified = true
	}

	i := 0

	// Copy elements in the part of the array that already had the necessary room.
	for ; i < minLen; i++ {
		if src.elems[i].canBeShared() {
			if src.elems[i].computeDiff(dst.elems[i]) {
				dst.elems[i] = src.elems[i]
				isModified = true
			}
		} else {
			copyJsonValue(dst.elems[i], src.elems[i])
			isModified = true
		}
	}
	if minLen < len(dst.elems) {
		isModified = true
		for ; i < len(dst.elems); i++ {
			if src.elems[i].canBeShared() {
				dst.elems[i] = src.elems[i]
				dst.elems[i].setModifiedRecursively()
			} else {
				dst.elems[i] = &JsonValue{}
				dst.elems[i].init(dst.parentModifiedFields, dst.parentModifiedBit)
				copyJsonValue(dst.elems[i], src.elems[i])
			}
		}
	}
	if isModified {
		dst.markModified()
	}
}

// Copy from src to dst. dst is assumed to be just inited.
func copyToNewJsonValueArray(dst *JsonValueArray, src *JsonValueArray, allocators *Allocators) {
	if len(src.elems) == 0 {
		return
	}

	dst.ensureLen(len(src.elems), allocators)
	// Need to allocate new elements for the part of the array that has grown.
	for j := 0; j < len(dst.elems); j++ {
		if src.elems[j].canBeShared() {
			dst.elems[j] = src.elems[j]
		} else {
			// Alloc and init the element.
			allocators.allocSizeChecker.AddAllocSize(uint(unsafe.Sizeof(JsonValue{})))
			dst.elems[j] = allocators.JsonValue.Alloc()
			dst.elems[j].initAlloc(dst.parentModifiedFields, dst.parentModifiedBit, allocators)
			// Copy the element.
			copyToNewJsonValue(dst.elems[j], src.elems[j], allocators)
		}
	}
}

// Len returns the number of elements in the array.
func (e *JsonValueArray) Len() int {
	return len(e.elems)
}

// At returns element at index i.
func (m *JsonValueArray) At(i int) *JsonValue {
	return m.elems[i]
}

// EnsureLen ensures the length of the array is equal to newLen.
// It will grow or shrink the array if needed.
func (e *JsonValueArray) EnsureLen(newLen int) {
	oldLen := len(e.elems)
	e.ensureLen(newLen, &Allocators{})
	for i := min(oldLen, newLen); i < newLen; i++ {
		// Reset newly created elements to initial state.
		e.elems[i].reset()
	}
}

// EnsureLen ensures the length of the array is equal to newLen.
// It will grow or shrink the array if needed.
func (e *JsonValueArray) ensureLen(newLen int, allocators *Allocators) {
	oldLen := len(e.elems)
	if newLen > oldLen {
		// Check if the underlying array is reallocated.
		beforePtr := unsafe.SliceData(e.elems)

		// Grow the array
		e.elems = pkg.EnsureLen(e.elems, newLen)

		e.markModified()
		// Initialize newly added elements.
		for i := e.initedCount; i < newLen; i++ {
			e.elems[i] = allocators.JsonValue.Alloc()
			e.elems[i].initAlloc(e.parentModifiedFields, e.parentModifiedBit, allocators)
		}
		if e.initedCount < newLen {
			e.initedCount = newLen
		}
		if beforePtr != unsafe.SliceData(e.elems) {
			// Underlying array was reallocated, we need to fix parent pointers
			// in all elements.
			for i := 0; i < newLen; i++ {
				e.elems[i].fixParent(e.parentModifiedFields)
			}
		}
	} else if oldLen > newLen {
		// Shrink it
		e.elems = e.elems[:newLen]
		e.markModified()
	}
}

// IsEqual performs deep comparison and returns true if array is equal to val.
func (e *JsonValueArray) IsEqual(val *JsonValueArray) bool {
	if len(e.elems) != len(val.elems) {
		return false
	}
	for i := range e.elems {
		if !e.elems[i].IsEqual(val.elems[i]) {
			return false
		}
	}
	return true
}

// CmpJsonValueArray performs deep comparison and returns an integer that
// will be 0 if left == right, negative if left < right, positive if left > right.
func CmpJsonValueArray(left, right *JsonValueArray) int {
	c := len(left.elems) - len(right.elems)
	if c != 0 {
		return c
	}
	for i := range left.elems {
		fc := CmpJsonValue(left.elems[i], right.elems[i])
		if fc != 0 {
			return fc
		}
	}
	return 0
}

// mutateRandom mutates fields in a random, deterministic manner using
// random parameter as a deterministic generator. If array elements contain structs/oneofs
// only fields that exist in the schema are mutated, allowing to generate data for
// specified schema.
func (a *JsonValueArray) mutateRandom(random *rand.Rand, schem *schema.Schema, limiter *mutateRandomLimiter) {
	if random.IntN(20) == 0 {
		if limiter.elemCount < mutateRandomMaxElems {
			a.EnsureLen(a.Len() + 1)
			limiter.elemCount++
		}
	}
	if random.IntN(20) == 0 && a.Len() > 0 {
		a.EnsureLen(a.Len() - 1)
	}

	for i := range a.elems {
		_ = i
		if random.IntN(2*len(a.elems)) == 0 {
			a.elems[i].mutateRandom(random, schem, limiter)
		}
	}
}

type JsonValueArrayEncoder struct {
	buf         pkg.BitsWriter
	limiter     *pkg.SizeLimiter
	elemEncoder *JsonValueEncoder
	isRecursive bool
	state       *WriterState
}

func (e *JsonValueArrayEncoder) Init(state *WriterState, columns *pkg.WriteColumnSet) error {
	e.state = state
	e.limiter = &state.limiter

	// Remember this encoder in the state so that we can detect recursion.
	if state.JsonValueArrayEncoder != nil {
		panic("cannot initialize JsonValueArrayEncoder: already initialized")
	}
	state.JsonValueArrayEncoder = e
	defer func() { state.JsonValueArrayEncoder = nil }()

	if state.JsonValueEncoder != nil {
		// Recursion detected, use the existing encoder.
		e.elemEncoder = state.JsonValueEncoder
		e.isRecursive = true
	} else {
		e.elemEncoder = new(JsonValueEncoder)
		if err := e.elemEncoder.Init(state, columns.AddSubColumn()); err != nil {
			return err
		}
	}

	return nil
}

func (e *JsonValueArrayEncoder) Reset() {
	if !e.isRecursive {
		e.elemEncoder.Reset()
	}
}

func (e *JsonValueArrayEncoder) Encode(arr *JsonValueArray) {
	oldBitLen := e.buf.BitCount()

	// Write the length of the array.
	newLen := len(arr.elems)
	e.buf.WriteUvarintCompact(uint64(newLen))

	// Encode the elements of the array.
	for i := 0; i < newLen; i++ {
		e.elemEncoder.Encode(arr.elems[i])
	}

	// Account written bits in the limiter.
	newBitLen := e.buf.BitCount()
	e.limiter.AddFrameBits(newBitLen - oldBitLen)
}

func (e *JsonValueArrayEncoder) CollectColumns(columnSet *pkg.WriteColumnSet) {
	columnSet.SetBits(&e.buf)
	if !e.isRecursive {
		e.elemEncoder.CollectColumns(columnSet.At(0))
	}
}

type JsonValueArrayDecoder struct {
	buf         pkg.BitsReader
	column      *pkg.ReadableColumn
	elemDecoder *JsonValueDecoder
	isRecursive bool
	allocators  *Allocators
}

// Init is called once in the lifetime of the stream.
func (d *JsonValueArrayDecoder) Init(state *ReaderState, columns *pkg.ReadColumnSet) error {
	d.column = columns.Column()
	// Remember this encoder in the state so that we can detect recursion.
	if state.JsonValueArrayDecoder != nil {
		panic("cannot initialize JsonValueArrayDecoder: already initialized")
	}
	state.JsonValueArrayDecoder = d
	defer func() { state.JsonValueArrayDecoder = nil }()

	if state.JsonValueDecoder != nil {
		d.elemDecoder = state.JsonValueDecoder
		d.isRecursive = true
	} else {
		d.elemDecoder = new(JsonValueDecoder)
		if err := d.elemDecoder.Init(state, columns.AddSubColumn()); err != nil {
			return err
		}
	}

	d.allocators = &state.Allocators

	return nil
}

// Continue is called at the start of the frame to continue decoding column data.
// This should set the decoder's source buffer, so the new decoding continues from
// the supplied column data. This should NOT reset the internal state of the decoder,
// since columns can cross frame boundaries and the new column data is considered
// continuation of that same column in the previous frame.
func (d *JsonValueArrayDecoder) Continue() {
	d.buf.Reset(d.column.Data())
	if !d.isRecursive {
		d.elemDecoder.Continue()
	}
}

func (d *JsonValueArrayDecoder) Reset() {
	if !d.isRecursive {
		d.elemDecoder.Reset()
	}
}

func (d *JsonValueArrayDecoder) Decode(dst *JsonValueArray) error {
	newLen := int(d.buf.ReadUvarintCompact())

	oldLen := len(dst.elems)

	// Account for allocation size.
	lenDelta := newLen - oldLen
	if lenDelta > 0 {
		if err := d.allocators.allocSizeChecker.PrepAllocSizeN(uint(lenDelta), uint(unsafe.Sizeof(dst.elems[0])+unsafe.Sizeof(JsonValue{}))); err != nil {
			return err
		}
	}

	dst.ensureLen(newLen, d.allocators)
	for i := min(oldLen, newLen); i < newLen; i++ {
		// Reset newly created keys to initial state.
		dst.elems[i].reset()
	}

	for i := 0; i < newLen; i++ {
		err := d.elemDecoder.Decode(dst.elems[i])
		if err != nil {
			return err
		}
	}

	return d.buf.Error()
}
