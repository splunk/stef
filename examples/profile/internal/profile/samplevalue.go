// Code generated by stefc. DO NOT EDIT.
package profile

import (
	"bytes"
	"fmt"
	"math/rand/v2"
	"strings"
	"unsafe"

	"github.com/splunk/stef/go/pkg"
	"github.com/splunk/stef/go/pkg/codecs"
	"github.com/splunk/stef/go/pkg/schema"
)

var _ = strings.Compare
var _ = codecs.StringEncoder{}
var _ = schema.WireSchema{}
var _ = bytes.NewBuffer

type SampleValue struct {
	val   int64
	type_ *SampleValueType

	// modifiedFields keeps track of which fields are modified.
	modifiedFields modifiedFields
}

const SampleValueStructName = "SampleValue"

// Bitmasks for "modified" flags for each field.
const (
	fieldModifiedSampleValueVal = uint64(1 << iota)
	fieldModifiedSampleValueType
)

// Init must be called once, before the SampleValue is used.
func (s *SampleValue) Init() {
	s.init(nil, 0)
}

func NewSampleValue() *SampleValue {
	var s SampleValue
	s.init(nil, 0)
	return &s
}

func (s *SampleValue) init(parentModifiedFields *modifiedFields, parentModifiedBit uint64) {
	s.modifiedFields.parent = parentModifiedFields
	s.modifiedFields.parentBit = parentModifiedBit

	s.type_ = &SampleValueType{}
	s.type_.init(&s.modifiedFields, fieldModifiedSampleValueType)
}

func (s *SampleValue) initAlloc(parentModifiedFields *modifiedFields, parentModifiedBit uint64, allocators *Allocators) {
	s.modifiedFields.parent = parentModifiedFields
	s.modifiedFields.parentBit = parentModifiedBit

	allocators.allocSizeChecker.AddAllocSize(uint(unsafe.Sizeof(SampleValueType{})))
	s.type_ = allocators.SampleValueType.Alloc()
	s.type_.initAlloc(&s.modifiedFields, fieldModifiedSampleValueType, allocators)
}

// reset the struct to its initial state, as if init() was just called.
// Will not reset internal fields such as parentModifiedFields.
func (s *SampleValue) reset() {
	if s.modifiedFields.isFrozen() {
		panic("cannot modify frozen SampleValue")
	}
	s.val = 0
	s.type_ = &emptySampleValueType
}

// fixParent sets the parentModifiedFields pointer to the supplied value.
// This is used when the parent is moved in memory for example because the parent
// an array element and the array was expanded.
func (s *SampleValue) fixParent(parentModifiedFields *modifiedFields) {
	s.modifiedFields.parent = parentModifiedFields
	s.type_.fixParent(&s.modifiedFields)
}

func (s *SampleValue) freeze() {
	if s.isFrozen() {
		return
	}
	s.modifiedFields.freeze()
	s.type_.freeze()
}

func (s *SampleValue) isFrozen() bool {
	return s.modifiedFields.isFrozen()
}

func (s *SampleValue) Val() int64 {
	return s.val
}

// SetVal sets the value of Val field.
func (s *SampleValue) SetVal(v int64) {
	if s.val != v {
		s.val = v
		s.modifiedFields.markModified(fieldModifiedSampleValueVal)
	}
}

func (s *SampleValue) markValModified() {
	s.modifiedFields.markModified(fieldModifiedSampleValueVal)
}

// IsValModified returns true the value of Val field was modified since
// SampleValue was created, encoded or decoded. If the field is modified
// it will be encoded by the next Write() operation. If the field is decoded by the
// next Read() operation the modified flag will be set.
func (s *SampleValue) IsValModified() bool {
	return s.modifiedFields.mask&fieldModifiedSampleValueVal != 0
}

// Type returns a readonly value. Use SetType() to modify it.
func (s *SampleValue) Type() *SampleValueType {
	return s.type_
}

// SetType sets the value of Type field.
func (s *SampleValue) SetType(v *SampleValueType) {
	if v.canBeShared() {
		// v can be shared by pointer. Compute its difference from current type_
		if v.computeDiff(s.type_) {
			// It is different. Update to it.
			s.type_ = v
			s.modifiedFields.markModified(fieldModifiedSampleValueType)
		}
	} else {
		if s.type_.canBeShared() {
			s.type_ = s.type_.Clone(&Allocators{})
		}
		s.type_.CopyFrom(v)
		s.modifiedFields.markModified(fieldModifiedSampleValueType)
	}
}

func (s *SampleValue) markTypeModified() {
	s.modifiedFields.markModified(fieldModifiedSampleValueType)
}

// IsTypeModified returns true the value of Type field was modified since
// SampleValue was created, encoded or decoded. If the field is modified
// it will be encoded by the next Write() operation. If the field is decoded by the
// next Read() operation the modified flag will be set.
func (s *SampleValue) IsTypeModified() bool {
	return s.modifiedFields.mask&fieldModifiedSampleValueType != 0
}

func (s *SampleValue) setModifiedRecursively() {
	s.type_.setModifiedRecursively()
	s.modifiedFields.mask =
		fieldModifiedSampleValueVal |
			fieldModifiedSampleValueType | 0
}

func (s *SampleValue) setUnmodifiedRecursively() {
	if s.IsTypeModified() {
		s.type_.setUnmodifiedRecursively()
	}
	s.modifiedFields.mask = 0
}

// computeDiff compares s and val and returns true if they differ.
// All fields that are different in s will be marked as modified.
func (s *SampleValue) computeDiff(val *SampleValue) (ret bool) {
	// Compare Val field.
	if s.val != val.val {
		s.modifiedFields.setModified(fieldModifiedSampleValueVal)
		ret = true
	}
	// Compare Type field.
	if s.type_.computeDiff(val.type_) {
		s.modifiedFields.setModified(fieldModifiedSampleValueType)
		ret = true
	}
	return ret
}

// canBeShared returns true if s is safe to share by pointer without cloning (for example if s is frozen).
func (s *SampleValue) canBeShared() bool {
	return false
}

// cloneShared returns a clone of s. It may return s if it is safe to share without cloning
// (for example if s is frozen).
func (s *SampleValue) cloneShared(allocators *Allocators) SampleValue {
	return s.Clone(allocators)
}

func (s *SampleValue) Clone(allocators *Allocators) SampleValue {
	c := SampleValue{
		val:   s.val,
		type_: s.type_.cloneShared(allocators),
	}
	return c
}

// ByteSize returns approximate memory usage in bytes. Used to calculate
// memory used by dictionaries.
func (s *SampleValue) byteSize() uint {
	return uint(unsafe.Sizeof(*s)) +
		s.type_.byteSize() + 0
}

// Copy from src to dst, overwriting existing data in dst.
func copySampleValue(dst *SampleValue, src *SampleValue) {
	dst.SetVal(src.val)

	if src.type_.canBeShared() {
		if src.type_.computeDiff(dst.type_) {
			dst.type_ = src.type_
			dst.markTypeModified()
		}
	} else {
		if dst.type_ == nil || dst.type_.canBeShared() { // Not allowed to modify shared data.
			dst.type_ = new(SampleValueType)
			dst.type_.init(&dst.modifiedFields, fieldModifiedSampleValueType)
		}
		copySampleValueType(dst.type_, src.type_)
	}
}

// Copy from src to dst. dst is assumed to be just inited.
func copyToNewSampleValue(dst *SampleValue, src *SampleValue, allocators *Allocators) {
	dst.SetVal(src.val)

	if src.type_.canBeShared() {
		dst.type_ = src.type_
	} else {
		allocators.allocSizeChecker.AddAllocSize(uint(unsafe.Sizeof(SampleValueType{})))
		dst.type_ = allocators.SampleValueType.Alloc()
		dst.type_.init(&dst.modifiedFields, fieldModifiedSampleValueType)
		copyToNewSampleValueType(dst.type_, src.type_, allocators)
	}

}

// CopyFrom() performs a deep copy from src.
func (s *SampleValue) CopyFrom(src *SampleValue) {
	copySampleValue(s, src)
}

// mutateRandom mutates fields in a random, deterministic manner using
// random parameter as a deterministic generator. Only fields that exist
// in the schem are mutated, allowing to generate data for specified schema.
// The state of "modified" flags is undefined after this operation.
func (s *SampleValue) mutateRandom(random *rand.Rand, schem *schema.Schema, limiter *mutateRandomLimiter) {
	// Get the field count for this struct from the schema. If the schema specifies
	// fewer field count than the one we have in this code then we will not mutate
	// fields that are not in the schema.
	fieldCount, err := schem.FieldCount("SampleValue")
	if err != nil {
		panic(fmt.Sprintf("cannot get field count for %s: %v", "SampleValue", err))
	}

	const randRange = max(2, 2) // At least 2 to ensure we don't recurse infinitely if there is only 1 field.

	if fieldCount <= 0 {
		return // Val and all subsequent fields are skipped.
	}
	// Maybe mutate Val
	if random.IntN(randRange) == 0 {
		s.SetVal(pkg.Int64Random(random))
	}
	if fieldCount <= 1 {
		return // Type and all subsequent fields are skipped.
	}
	// Maybe mutate Type
	if random.IntN(randRange) == 0 {
		if random.IntN(10) == 0 {
			// Freeze and replace with a clone to test frozen object dictionary handling.
			s.type_.Freeze()
			if random.IntN(10) == 0 {
				// Reset to brand new object once in a while to test the code path
				// where a dict-based is not mutated, but created from scratch.
				s.type_ = new(SampleValueType)
				s.type_.init(&s.modifiedFields, fieldModifiedSampleValueType)
			} else {
				s.type_ = s.type_.Clone(&Allocators{})
			}
		}
		if s.type_.canBeShared() {
			// type_ may be shared by pointer. Clone it to have exclusive ownership.
			s.type_ = s.type_.Clone(&Allocators{})
		}

		s.type_.mutateRandom(random, schem, limiter)
	}
}

// IsEqual performs deep comparison and returns true if struct is equal to right.
func (s *SampleValue) IsEqual(right *SampleValue) bool {
	// Compare Val field.
	if !pkg.Int64Equal(s.val, right.val) {
		return false
	}
	// Compare Type field.
	if !s.type_.IsEqual(right.type_) {
		return false
	}

	return true
}

// CmpSampleValue performs deep comparison and returns an integer that
// will be 0 if left == right, negative if left < right, positive if left > right.
func CmpSampleValue(left, right *SampleValue) int {
	// Compare Val field.
	if c := pkg.Int64Compare(left.val, right.val); c != 0 {
		return c
	}
	// Compare Type field.
	if c := CmpSampleValueType(left.type_, right.type_); c != 0 {
		return c
	}
	return 0
}

// SampleValueEncoder implements encoding of SampleValue
type SampleValueEncoder struct {
	buf     pkg.BitsWriter
	limiter *pkg.SizeLimiter

	// forceModifiedFields is set to a mask to force the next encoding operation
	// write the fields, whether they are modified or no. This is used after frame
	// restarts so that the data can be decoded from the frame start.
	forceModifiedFields uint64

	valEncoder      codecs.Int64Encoder
	type_Encoder    *SampleValueTypeEncoder
	isTypeRecursive bool // Indicates Type field's type is recursive.

	allocators *Allocators

	keepFieldMask uint64
	fieldCount    uint
}

func (e *SampleValueEncoder) Init(state *WriterState, columns *pkg.WriteColumnSet) error {
	// Remember this encoder in the state so that we can detect recursion.
	if state.SampleValueEncoder != nil {
		panic("cannot initialize SampleValueEncoder: already initialized")
	}
	state.SampleValueEncoder = e
	defer func() { state.SampleValueEncoder = nil }()

	e.limiter = &state.limiter
	e.allocators = &state.Allocators

	// Number of fields in the output data schema.
	var err error
	e.fieldCount, err = state.StructFieldCounts.SampleValueFieldCount()
	if err != nil {
		return fmt.Errorf("cannot find struct %s in override schema: %w", "SampleValue", err)
	}
	// Set that many 1 bits in the keepFieldMask. All fields with higher number
	// will be skipped when encoding.
	e.keepFieldMask = ^(^uint64(0) << e.fieldCount)

	// Init encoder for Val field.
	if e.fieldCount <= 0 {
		return nil // Val and all subsequent fields are skipped.
	}
	err = e.valEncoder.Init(e.limiter, columns.AddSubColumn())
	if err != nil {
		return err
	}

	// Init encoder for Type field.
	if e.fieldCount <= 1 {
		return nil // Type and all subsequent fields are skipped.
	}
	if state.SampleValueTypeEncoder != nil {
		// Recursion detected, use the existing encoder.
		e.type_Encoder = state.SampleValueTypeEncoder
		e.isTypeRecursive = true
	} else {
		e.type_Encoder = new(SampleValueTypeEncoder)
		err = e.type_Encoder.Init(state, columns.AddSubColumn())
	}
	if err != nil {
		return err
	}

	return nil
}

func (e *SampleValueEncoder) Reset() {
	// Since we are resetting the state of encoder make sure the next Encode()
	// call forcedly writes all fields and does not attempt to skip.
	e.forceModifiedFields = e.keepFieldMask

	if e.fieldCount <= 0 {
		return // Val and all subsequent fields are skipped.
	}
	e.valEncoder.Reset()
	if e.fieldCount <= 1 {
		return // Type and all subsequent fields are skipped.
	}
	if !e.isTypeRecursive {
		e.type_Encoder.Reset()
	}
}

// Encode encodes val into buf
func (e *SampleValueEncoder) Encode(val *SampleValue) {
	var bitCount uint

	// Mask that describes what fields are encoded. Start with all modified fields.
	fieldMask := val.modifiedFields.mask

	// If forceModifiedFields we need to set to 1 all bits so that we
	// force writing of all fields.
	fieldMask |= e.forceModifiedFields
	e.forceModifiedFields = 0

	// Only write fields that we want to write. See Init() for keepFieldMask.
	fieldMask &= e.keepFieldMask

	// Write bits to indicate which fields follow.
	e.buf.WriteBits(fieldMask, e.fieldCount)
	bitCount += e.fieldCount

	// Encode modified, present fields.

	if fieldMask&fieldModifiedSampleValueVal != 0 {
		// Encode Val
		e.valEncoder.Encode(val.val)
	}

	if fieldMask&fieldModifiedSampleValueType != 0 {
		// Encode Type
		e.type_Encoder.Encode(val.type_)
	}

	// Account written bits in the limiter.
	e.limiter.AddFrameBits(bitCount)

	// Mark all fields non-modified so that next Encode() correctly
	// encodes only fields that change after this.
	val.modifiedFields.mask = 0
}

// CollectColumns collects all buffers from all encoders into buf.
func (e *SampleValueEncoder) CollectColumns(columnSet *pkg.WriteColumnSet) {
	columnSet.SetBits(&e.buf)
	colIdx := 0
	// Collect Val field.
	if e.fieldCount <= 0 {
		return // Val and subsequent fields are skipped.
	}
	e.valEncoder.CollectColumns(columnSet.At(colIdx))
	colIdx++
	// Collect Type field.
	if e.fieldCount <= 1 {
		return // Type and subsequent fields are skipped.
	}
	if !e.isTypeRecursive {
		e.type_Encoder.CollectColumns(columnSet.At(colIdx))
		colIdx++
	}
}

// SampleValueDecoder implements decoding of SampleValue
type SampleValueDecoder struct {
	buf        pkg.BitsReader
	column     *pkg.ReadableColumn
	fieldCount uint

	valDecoder codecs.Int64Decoder

	type_Decoder    *SampleValueTypeDecoder
	isTypeRecursive bool
	allocators      *Allocators
}

// Init is called once in the lifetime of the stream.
func (d *SampleValueDecoder) Init(state *ReaderState, columns *pkg.ReadColumnSet) error {
	// Remember this decoder in the state so that we can detect recursion.
	if state.SampleValueDecoder != nil {
		panic("cannot initialize SampleValueDecoder: already initialized")
	}
	state.SampleValueDecoder = d
	defer func() { state.SampleValueDecoder = nil }()

	d.allocators = &state.Allocators

	// Number of fields in the input data schema.
	var err error
	d.fieldCount, err = state.StructFieldCounts.SampleValueFieldCount()
	if err != nil {
		return fmt.Errorf("cannot find struct %s in override schema: %w", "SampleValue", err)
	}
	if d.fieldCount > 2 {
		return pkg.ErrTooManyFieldsToDecode
	}

	d.column = columns.Column()

	if d.fieldCount <= 0 {
		return nil // Val and subsequent fields are skipped.
	}
	err = d.valDecoder.Init(columns.AddSubColumn())
	if err != nil {
		return err
	}
	if d.fieldCount <= 1 {
		return nil // Type and subsequent fields are skipped.
	}
	if state.SampleValueTypeDecoder != nil {
		// Recursion detected, use the existing decoder.
		d.type_Decoder = state.SampleValueTypeDecoder
		d.isTypeRecursive = true // Mark that we are using a recursive decoder.
	} else {
		d.type_Decoder = new(SampleValueTypeDecoder)
		err = d.type_Decoder.Init(state, columns.AddSubColumn())
	}
	if err != nil {
		return err
	}

	return nil
}

// Continue is called at the start of the frame to continue decoding column data.
// This should set the decoder's source buffer, so the new decoding continues from
// the supplied column data. This should NOT reset the internal state of the decoder,
// since columns can cross frame boundaries and the new column data is considered
// continuation of that same column in the previous frame.
func (d *SampleValueDecoder) Continue() {
	d.buf.Reset(d.column.Data())

	if d.fieldCount <= 0 {
		return // Val and subsequent fields are skipped.
	}
	d.valDecoder.Continue()
	if d.fieldCount <= 1 {
		return // Type and subsequent fields are skipped.
	}

	if !d.isTypeRecursive {
		d.type_Decoder.Continue()
	}

}

func (d *SampleValueDecoder) Reset() {

	if d.fieldCount <= 0 {
		return // Val and all subsequent fields are skipped.
	}
	d.valDecoder.Reset()
	if d.fieldCount <= 1 {
		return // Type and all subsequent fields are skipped.
	}

	if !d.isTypeRecursive {
		d.type_Decoder.Reset()
	}

}

func (d *SampleValueDecoder) Decode(dstPtr *SampleValue) error {
	val := dstPtr

	var err error

	// Read bits that indicate which fields follow.
	val.modifiedFields.mask = d.buf.PeekBits(d.fieldCount)
	d.buf.Consume(d.fieldCount)

	if val.modifiedFields.mask&fieldModifiedSampleValueVal != 0 { // Val is changed.

		err = d.valDecoder.Decode(&val.val)
		if err != nil {
			return err
		}
	}

	if val.modifiedFields.mask&fieldModifiedSampleValueType != 0 { // Type is changed.

		if val.type_ == nil {
			if err := d.allocators.allocSizeChecker.PrepAllocSize(uint(unsafe.Sizeof(*val.type_))); err != nil {
				return err
			}
			val.type_ = d.allocators.SampleValueType.Alloc()
			val.type_.init(&val.modifiedFields, fieldModifiedSampleValueType)
		}

		err = d.type_Decoder.Decode(&val.type_)
		if err != nil {
			return err
		}
	}

	return d.buf.Error()
}

// SampleValueAllocator implements a custom allocator for SampleValue.
// It maintains a pool of pre-allocated SampleValue and grows the pool
// dynamically as needed, up to a maximum size of 64 elements.
type SampleValueAllocator struct {
	pool []SampleValue
	ofs  int
}

// Alloc returns the next available SampleValue from the pool.
// If the pool is exhausted, it grows the pool by doubling its size
// up to a maximum of 64 elements.
func (a *SampleValueAllocator) Alloc() *SampleValue {
	if a.ofs < len(a.pool) {
		// Get the next available SampleValue from the pool
		a.ofs++
		return &a.pool[a.ofs-1]
	}
	// We've exhausted the current pool, prealloc a new pool.
	return a.prealloc()
}

//go:noinline
func (a *SampleValueAllocator) prealloc() *SampleValue {
	// prealloc expands the pool by doubling its size, up to a maximum of 64 elements.
	// If the pool is empty, it starts with 1 element.
	newLen := min(max(len(a.pool)*2, 1), 64)
	a.pool = make([]SampleValue, newLen)
	a.ofs = 1
	return &a.pool[0]
}
